#!/usr/bin/env python3
"""
vLLMæœåŠ¡é…ç½®æ–‡ä»¶
ç”¨äºç®¡ç†vLLMæœåŠ¡çš„å„ç§é…ç½®å‚æ•°
"""

import os
from typing import Dict, Any

class VLLMConfig:
    """vLLMæœåŠ¡é…ç½®ç±»"""
    
    # æœåŠ¡é…ç½®
    SERVICE_HOST = "127.0.0.1"
    SERVICE_PORT = 5000
    SERVICE_URL = f"http://{SERVICE_HOST}:{SERVICE_PORT}"
    
    # æ¨¡å‹é…ç½®
    MODEL_PATH = "/fs-computility/video/shared/hf_weight/Qwen3-32B"
    MODEL_CONFIG = {
        "trust_remote_code": True,
        "dtype": "auto",
        "gpu_memory_utilization": 0.9,
        "max_model_len": 8192,
        "enforce_eager": True,
    }
    
    # æ¨ç†é…ç½®
    SAMPLING_CONFIG = {
        "temperature": 0.0,
        "max_tokens": 64,
        "stop": ["<|im_end|>", "<|endoftext|>", "\n\n"]
    }
    
    # è¯·æ±‚é…ç½®
    REQUEST_CONFIG = {
        "timeout": 30,
        "retry_times": 3,
        "retry_delay": 1.0
    }
    
    # ç¯å¢ƒå˜é‡
    ENV_VARS = {
        "CUDA_VISIBLE_DEVICES": "0",
        "VLLM_USE_TRITON_KERNEL": "1",  # å¯ç”¨Tritonå†…æ ¸ä¼˜åŒ–
    }
    
    @classmethod
    def get_service_url(cls) -> str:
        """è·å–æœåŠ¡URL"""
        return cls.SERVICE_URL
    
    @classmethod
    def get_model_config(cls) -> Dict[str, Any]:
        """è·å–æ¨¡å‹é…ç½®"""
        return cls.MODEL_CONFIG.copy()
    
    @classmethod
    def get_sampling_config(cls) -> Dict[str, Any]:
        """è·å–é‡‡æ ·é…ç½®"""
        return cls.SAMPLING_CONFIG.copy()
    
    @classmethod
    def get_request_config(cls) -> Dict[str, Any]:
        """è·å–è¯·æ±‚é…ç½®"""
        return cls.REQUEST_CONFIG.copy()
    
    @classmethod
    def setup_environment(cls):
        """è®¾ç½®ç¯å¢ƒå˜é‡"""
        for key, value in cls.ENV_VARS.items():
            os.environ[key] = value
    
    @classmethod
    def validate_config(cls) -> bool:
        """éªŒè¯é…ç½®æ˜¯å¦æœ‰æ•ˆ"""
        try:
            # æ£€æŸ¥æ¨¡å‹è·¯å¾„æ˜¯å¦å­˜åœ¨
            if not os.path.exists(cls.MODEL_PATH):
                print(f"âŒ æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {cls.MODEL_PATH}")
                return False
            
            # æ£€æŸ¥ç«¯å£æ˜¯å¦åœ¨æœ‰æ•ˆèŒƒå›´å†…
            if not (1 <= cls.SERVICE_PORT <= 65535):
                print(f"âŒ ç«¯å£å·æ— æ•ˆ: {cls.SERVICE_PORT}")
                return False
            
            # æ£€æŸ¥GPUå†…å­˜ä½¿ç”¨ç‡
            if not (0.1 <= cls.MODEL_CONFIG["gpu_memory_utilization"] <= 1.0):
                print(f"âŒ GPUå†…å­˜ä½¿ç”¨ç‡æ— æ•ˆ: {cls.MODEL_CONFIG['gpu_memory_utilization']}")
                return False
            
            print("âœ… é…ç½®éªŒè¯é€šè¿‡")
            return True
            
        except Exception as e:
            print(f"âŒ é…ç½®éªŒè¯å¤±è´¥: {e}")
            return False

# é»˜è®¤é…ç½®å®ä¾‹
config = VLLMConfig()

if __name__ == "__main__":
    # æµ‹è¯•é…ç½®
    print("ğŸ”§ vLLMé…ç½®æµ‹è¯•")
    print("=" * 40)
    
    print(f"æœåŠ¡URL: {config.get_service_url()}")
    print(f"æ¨¡å‹è·¯å¾„: {config.MODEL_PATH}")
    print(f"GPUå†…å­˜ä½¿ç”¨ç‡: {config.MODEL_CONFIG['gpu_memory_utilization']}")
    print(f"æœ€å¤§åºåˆ—é•¿åº¦: {config.MODEL_CONFIG['max_model_len']}")
    
    # éªŒè¯é…ç½®
    if config.validate_config():
        print("\nğŸ‰ é…ç½®æµ‹è¯•é€šè¿‡!")
    else:
        print("\nâŒ é…ç½®æµ‹è¯•å¤±è´¥!") 