#!/usr/bin/env python3
"""
vLLMæœåŠ¡ç›‘æ§è„šæœ¬
ç›‘æ§æœåŠ¡çŠ¶æ€ã€æ€§èƒ½æŒ‡æ ‡å’Œèµ„æºä½¿ç”¨æƒ…å†µ
"""

import requests
import time
import psutil
import GPUtil
import json
from datetime import datetime
from typing import Dict, Any, Optional

class VLLMServiceMonitor:
    """vLLMæœåŠ¡ç›‘æ§å™¨"""
    
    def __init__(self, service_url: str = "http://127.0.0.1:5000"):
        self.service_url = service_url
        self.monitoring = False
        
    def check_service_health(self) -> Dict[str, Any]:
        """æ£€æŸ¥æœåŠ¡å¥åº·çŠ¶æ€"""
        try:
            start_time = time.time()
            response = requests.get(f"{self.service_url}/", timeout=5)
            end_time = time.time()
            
            response_time = end_time - start_time
            
            if response.status_code == 404:  # Flaské»˜è®¤è¿”å›404ï¼Œè¯´æ˜æœåŠ¡åœ¨è¿è¡Œ
                return {
                    "status": "healthy",
                    "response_time": response_time,
                    "timestamp": datetime.now().isoformat(),
                    "error": None
                }
            else:
                return {
                    "status": "unhealthy",
                    "response_time": response_time,
                    "timestamp": datetime.now().isoformat(),
                    "error": f"HTTP {response.status_code}"
                }
                
        except requests.exceptions.ConnectionError:
            return {
                "status": "down",
                "response_time": None,
                "timestamp": datetime.now().isoformat(),
                "error": "Connection refused"
            }
        except Exception as e:
            return {
                "status": "error",
                "response_time": None,
                "timestamp": datetime.now().isoformat(),
                "error": str(e)
            }
    
    def get_system_resources(self) -> Dict[str, Any]:
        """è·å–ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ"""
        try:
            # CPUä½¿ç”¨ç‡
            cpu_percent = psutil.cpu_percent(interval=1)
            
            # å†…å­˜ä½¿ç”¨æƒ…å†µ
            memory = psutil.virtual_memory()
            
            # GPUä½¿ç”¨æƒ…å†µ
            gpu_info = {}
            try:
                gpus = GPUtil.getGPUs()
                for i, gpu in enumerate(gpus):
                    gpu_info[f"gpu_{i}"] = {
                        "name": gpu.name,
                        "memory_total": gpu.memoryTotal,
                        "memory_used": gpu.memoryUsed,
                        "memory_free": gpu.memoryFree,
                        "memory_percent": gpu.memoryUtil * 100,
                        "temperature": gpu.temperature,
                        "load": gpu.load * 100
                    }
            except Exception as e:
                gpu_info = {"error": str(e)}
            
            return {
                "cpu_percent": cpu_percent,
                "memory": {
                    "total": memory.total,
                    "available": memory.available,
                    "used": memory.used,
                    "percent": memory.percent
                },
                "gpu": gpu_info,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    def test_inference_performance(self) -> Dict[str, Any]:
        """æµ‹è¯•æ¨ç†æ€§èƒ½"""
        test_data = {
            "content": "è¿™æ˜¯ä¸€å¼ æµ‹è¯•å›¾ç‰‡ï¼Œæ˜¾ç¤ºäº†ä¸€ä¸ªçº¢è‰²çš„è‹¹æœã€‚",
            "sol": "<answer>è‹¹æœ</answer>",
            "problem_type": "caption",
            "problem": "å›¾ç‰‡ä¸­æœ‰ä»€ä¹ˆæ°´æœï¼Ÿ"
        }
        
        try:
            start_time = time.time()
            response = requests.post(
                f"{self.service_url}/predict",
                json=test_data,
                timeout=30
            )
            end_time = time.time()
            
            if response.status_code == 200:
                result = response.json()
                return {
                    "status": "success",
                    "response_time": end_time - start_time,
                    "output": result.get("output"),
                    "timestamp": datetime.now().isoformat(),
                    "error": None
                }
            else:
                return {
                    "status": "failed",
                    "response_time": end_time - start_time,
                    "output": None,
                    "timestamp": datetime.now().isoformat(),
                    "error": f"HTTP {response.status_code}"
                }
                
        except Exception as e:
            return {
                "status": "error",
                "response_time": None,
                "output": None,
                "timestamp": datetime.now().isoformat(),
                "error": str(e)
            }
    
    def generate_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆç›‘æ§æŠ¥å‘Š"""
        health = self.check_service_health()
        resources = self.get_system_resources()
        performance = self.test_inference_performance()
        
        return {
            "health": health,
            "resources": resources,
            "performance": performance,
            "summary": {
                "service_status": health["status"],
                "cpu_usage": resources.get("cpu_percent", 0),
                "memory_usage": resources.get("memory", {}).get("percent", 0),
                "avg_response_time": performance.get("response_time", 0),
                "timestamp": datetime.now().isoformat()
            }
        }
    
    def print_report(self, report: Dict[str, Any]):
        """æ‰“å°ç›‘æ§æŠ¥å‘Š"""
        print(f"\nğŸ“Š vLLMæœåŠ¡ç›‘æ§æŠ¥å‘Š - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 60)
        
        # æœåŠ¡çŠ¶æ€
        health = report["health"]
        print(f"ğŸ” æœåŠ¡çŠ¶æ€: {health['status']}")
        if health['response_time']:
            print(f"   å“åº”æ—¶é—´: {health['response_time']:.3f}s")
        if health['error']:
            print(f"   é”™è¯¯ä¿¡æ¯: {health['error']}")
        
        # ç³»ç»Ÿèµ„æº
        resources = report["resources"]
        if "error" not in resources:
            print(f"\nğŸ’» ç³»ç»Ÿèµ„æº:")
            print(f"   CPUä½¿ç”¨ç‡: {resources['cpu_percent']:.1f}%")
            
            memory = resources['memory']
            print(f"   å†…å­˜ä½¿ç”¨ç‡: {memory['percent']:.1f}%")
            print(f"   å†…å­˜ä½¿ç”¨: {memory['used'] // (1024**3):.1f}GB / {memory['total'] // (1024**3):.1f}GB")
            
            # GPUä¿¡æ¯
            if "error" not in resources['gpu']:
                print(f"\nğŸ® GPUçŠ¶æ€:")
                for gpu_id, gpu in resources['gpu'].items():
                    print(f"   {gpu_id}: {gpu['name']}")
                    print(f"     æ˜¾å­˜ä½¿ç”¨: {gpu['memory_used']}MB / {gpu['memory_total']}MB ({gpu['memory_percent']:.1f}%)")
                    print(f"     æ¸©åº¦: {gpu['temperature']}Â°C")
                    print(f"     è´Ÿè½½: {gpu['load']:.1f}%")
        
        # æ€§èƒ½æµ‹è¯•
        performance = report["performance"]
        print(f"\nâš¡ æ€§èƒ½æµ‹è¯•:")
        print(f"   çŠ¶æ€: {performance['status']}")
        if performance['response_time']:
            print(f"   å“åº”æ—¶é—´: {performance['response_time']:.3f}s")
        if performance['output'] is not None:
            print(f"   è¾“å‡º: {performance['output']}")
        if performance['error']:
            print(f"   é”™è¯¯: {performance['error']}")
        
        # æ€»ç»“
        summary = report["summary"]
        print(f"\nğŸ“ˆ æ€»ç»“:")
        print(f"   æœåŠ¡çŠ¶æ€: {summary['service_status']}")
        print(f"   CPUä½¿ç”¨ç‡: {summary['cpu_usage']:.1f}%")
        print(f"   å†…å­˜ä½¿ç”¨ç‡: {summary['memory_usage']:.1f}%")
        print(f"   å¹³å‡å“åº”æ—¶é—´: {summary['avg_response_time']:.3f}s")
    
    def start_monitoring(self, interval: int = 30):
        """å¼€å§‹æŒç»­ç›‘æ§"""
        print(f"ğŸš€ å¼€å§‹ç›‘æ§vLLMæœåŠ¡ (é—´éš”: {interval}ç§’)")
        print(f"æœåŠ¡åœ°å€: {self.service_url}")
        print("æŒ‰ Ctrl+C åœæ­¢ç›‘æ§")
        
        self.monitoring = True
        
        try:
            while self.monitoring:
                report = self.generate_report()
                self.print_report(report)
                
                if interval > 0:
                    print(f"\nâ° {interval}ç§’åé‡æ–°æ£€æŸ¥...")
                    time.sleep(interval)
                else:
                    break
                    
        except KeyboardInterrupt:
            print("\n\nâ¹ï¸ ç›‘æ§å·²åœæ­¢")
            self.monitoring = False

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="vLLMæœåŠ¡ç›‘æ§å·¥å…·")
    parser.add_argument("--url", default="http://127.0.0.1:5000", help="æœåŠ¡URL")
    parser.add_argument("--once", action="store_true", help="åªæ£€æŸ¥ä¸€æ¬¡")
    parser.add_argument("--interval", type=int, default=30, help="ç›‘æ§é—´éš”(ç§’)")
    
    args = parser.parse_args()
    
    monitor = VLLMServiceMonitor(args.url)
    
    if args.once:
        # åªæ£€æŸ¥ä¸€æ¬¡
        report = monitor.generate_report()
        monitor.print_report(report)
    else:
        # æŒç»­ç›‘æ§
        monitor.start_monitoring(args.interval)

if __name__ == "__main__":
    main() 